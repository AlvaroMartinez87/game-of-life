{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlvaroMartinez87/game-of-life/blob/master/Paralelizacion_Python_AlvaroMartinez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s57otIsB_xKo"
      },
      "source": [
        "# PARALELIZACIÓN EN PYTHON"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algunas diferencias entre Python y C/C++\n",
        "\n",
        "**Python** | **C/C++**\n",
        "----------------- | ---------------------------\n",
        "**Interpretado** | **Compilado**\n",
        "**Multiplataforma** | La compilación crea **código específico** para cada plataforma\n",
        "**Flexiblidad**: listas que pueden contener listas, <br> diccionarios, funciones (y cualquier tipo de dato) | **Velocidad**: la compatibilidad en las operaciones <br> se resuelve en tiempo de compilación\n",
        "**Tipado dinámico** | **Tipado estático**: es necesario declarar el tipo de las variables\n",
        "Orientado a un **desarrollo rápido** | Orientado a una **ejecución rápida**"
      ],
      "metadata": {
        "id": "BzknHoD8VHvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algunas opciones para acelerar programas Python\n",
        "\n",
        "* Paralelizando con hilos: threading \n",
        "* Paralelizando con procesos: multiprocessing\n",
        "* Cython\n",
        "* pyCUDA\n",
        "* Numba"
      ],
      "metadata": {
        "id": "CbDF7PrjY9K-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PARALALIZANDO CON HILOS: `threading`\n",
        "\n",
        "El módulo `threading` permite crear hilos:\n",
        "\n",
        "https://docs.python.org/3/library/threading.html\n"
      ],
      "metadata": {
        "id": "9YWbcMppZ_19"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM6klfaF_xKt"
      },
      "source": [
        "Veamos con un ejemplo cómo podemos podemos descomponer un programa en hilos.\n",
        "\n",
        "Importamos la clase `time` para medir los tiempos de ejecución y comprobar el rendimiento del programa."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "kEHAUvYcbI5Y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecutemos primero un programa que cuenta un número de veces muy grande, por ejemplo 100.000.000 de veces, y veamos el tiempo que tarda."
      ],
      "metadata": {
        "id": "q9X2cUhQbJUp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HUfb2r0S_xKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7995baf2-1b3e-464b-a007-c319a935e931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo (en segundos) 34.45917248725891\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "VALOR = 500000000\n",
        "\n",
        "def cuentra_atras(n):\n",
        "    while n > 0:\n",
        "        n -= 1\n",
        "\n",
        "inicio = time.time()\n",
        "cuentra_atras(VALOR)\n",
        "fin = time.time()\n",
        "\n",
        "print('Tiempo (en segundos)', fin - inicio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVSbgimM_xKt"
      },
      "source": [
        "Intentemos acelerar el programa creando tres hilos y repartiendo la cuenta entre los tres hilos. Cada hilo contará la tercera parte del número total de veces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WO6vU_G_xKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c09a9158-68c8-48d7-badd-8229bc311fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo (en segundos) 7.163172245025635\n"
          ]
        }
      ],
      "source": [
        "# import time\n",
        "from threading import Thread\n",
        "\n",
        "VALOR = 100000000\n",
        "\n",
        "def cuentra_atras(n):\n",
        "    while n > 0:\n",
        "        n -= 1\n",
        "\n",
        "t1 = Thread(target=cuentra_atras, args=(VALOR//3,))\n",
        "t2 = Thread(target=cuentra_atras, args=(VALOR//3,))\n",
        "t3 = Thread(target=cuentra_atras, args=(VALOR//3,))\n",
        "\n",
        "inicio = time.time()\n",
        "t1.start()\n",
        "t2.start()\n",
        "t3.start()\n",
        "t1.join()\n",
        "t2.join()\n",
        "t3.join()\n",
        "fin = time.time()\n",
        "\n",
        "print('Tiempo (en segundos)', fin - inicio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgH5yqy-_xKu"
      },
      "source": [
        "Podemos comprobar que ambas versiones tardan un tiempo parecido, incluso puede que la versión con hilos tarde un poco más. Esto se debe al **GIL: Global Interpreter Lock**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZK7BzYk_xKr"
      },
      "source": [
        "## ¿Qué es el GIL (Global Interpreter Lock) de Python?\n",
        "\n",
        "El [GIL](https://wiki.python.org/moin/GlobalInterpreterLock) es un mutex que permite que sólo un hilo tome el control del intérprete de Python, es decir, que solo un hilo puede estar en ejecución a la vez. el GIL impide que los hilos se ejecuten en paralelo, y reparte el tiempo de CPU entre los hilos. **Se ejecutan concurrentemente pero no paralelamente**.\n",
        "\n",
        "![GIL]( https://drive.google.com/uc?id=1UFwYUV1ZRgzlqJxKtXH3O8AlQ8ipWo4r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmHKZY3K_xKs"
      },
      "source": [
        "### El conteo de referencias\n",
        "\n",
        "Python usa el **conteo de referencias** para la gestión de memoria. Cada objeto creado en Python tienen un contador de referencias que registra el número de referencias activas que apuntan a ese objeto. Cuando este contador llega a 0, el recolector de basura libera la memoria asignada a ese objeto porque entiende que ya no se está utilizando. **GIL impide que los hilos modifiquen este contador de referencias mientras otros hilos estén haciendo uso del objeto**. Si se tiene varios hilos ejecutando  concurrentemente, podría ocurrir que un hilo le indique al intérprete que un objeto se ha dejado de utilizar, cuando realmente otro hilo aun sigue trabajando con él. \n",
        "\n",
        "Para evitar este problema se implementó GIL, limitando que sólo un hilo tome el control del intérprete de Python.\n",
        "\n",
        "Veamos con un ejemplo el conteo de referencias. En este caso obtenemos como resultado 3, ya que la variable A cuenta con tres referencias: en las dos asignaciones y en la llamada a la función."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "C66hj6Ai_xKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d88607-192c-4d28-b4b3-6821d5b8e77c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo (en segundos) 1.3589859008789062e-05\n"
          ]
        }
      ],
      "source": [
        "# import time\n",
        "import sys\n",
        "\n",
        "A = []\n",
        "B = A\n",
        "sys.getrefcount(A)\n",
        "\n",
        "inicio = time.time()\n",
        "fin = time.time()\n",
        "\n",
        "print('Tiempo (en segundos)', fin - inicio)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "GIL favorece a los programas de un único hilo, pero perjudica a los programas multihilo con mucha carga de CPU. **El uso de hilos con `threading` es más adecuado para ejecutar simultáneamente varias tareas con carga de I/O.**\n",
        "\n",
        "Python tiene múltiples implementaciones de intérpretes. Por ejemplo, CPython, Jython, IronPython o PyPy. **GIL existe únicamente en la implementación original de Python que es CPython**."
      ],
      "metadata": {
        "id": "zQ7zghY36Haq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PARALALIZANDO CON PROCESOS: `multiprocessing`\n",
        "\n",
        "El módulo `multiprocessing` permite crear procesos:\n",
        "\n",
        "https://docs.python.org/3/library/multiprocessing.html\n",
        "\n"
      ],
      "metadata": {
        "id": "xutQgfk1pN7K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOQ-7hCC_xKu"
      },
      "source": [
        "## Cómo evitar el GIL\n",
        "\n",
        "Si queremos que las tareas se ejecuten de forma paralela debemos usar **multiples procesos en lugar de múltiples hilos**. De esta forma cada proceso ejecutará su propio intérprete Python y tendrá su propio espacio de memoria, logrando así evitar el cuello de botella del GIL.\n",
        "\n",
        "### El módulo multiprocessing\n",
        "https://docs.python.org/3/library/multiprocessing.html\n",
        "\n",
        "Hay 2 clases principales en el módulo multiprocessing para implementar la ejecución paralela de una función: la clase Process y la clase Pool.\n",
        "\n",
        "1. Clase Process\n",
        "\n",
        "2. Clase Pool \n",
        "   1. Ejecución síncrona\n",
        "      * Pool.map() y Pool.starmap()\n",
        "      * Pool.apply()\n",
        "   2. Ejecución asíncrona\n",
        "      * Pool.map_async() y Pool.starmap_async()\n",
        "      * Pool.apply_async())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4315L3n_xKu"
      },
      "source": [
        "Para ilustrar cómo se puede paralelizar en Python vamos a crear un función que cuente cuántas veces aparece en cada fila de una matriz bidimensional un número entero dado.\n",
        "\n",
        "Definimos primero un matriz de enteros aleatorios. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_gcmCAyv_xKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eccbe50c-9182-48d8-9bc0-8ba4f37d7249"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 0, 4, 8, 6, 7, 7, 0, 1, 5],\n",
              " [0, 8, 6, 8, 9, 4, 0, 8, 3, 9],\n",
              " [6, 0, 2, 9, 9, 6, 0, 0, 3, 7],\n",
              " [5, 8, 9, 3, 5, 1, 1, 0, 5, 5],\n",
              " [2, 3, 5, 2, 7, 7, 1, 9, 8, 8]]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import numpy as np\n",
        "from time import time\n",
        "\n",
        "# Preparamos los datos. Matriz de 1000x10\n",
        "np.random.RandomState(80)\n",
        "array = np.random.randint(0, 10, size=[10000000, 10])\n",
        "datos = array.tolist()\n",
        "\n",
        "# Mostramos las 5 primeras filas\n",
        "datos[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q28Spbr5_xKv"
      },
      "source": [
        "## Implementación sin paralelizar\n",
        "\n",
        "Definimos la función `n_veces` que cuenta las veces que aparece un número dado en una fila. Luego iteramos la función sobre las filas de la matriz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "E-94Wj6i_xKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa62a043-8b9a-4a4e-c5a5-94e50973ca9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 0, 0, 0, 0, 1, 1, 1, 1]\n",
            "Tiempo (en segundos) 2.2411346435546875e-05\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "# Implementación sin paralelizar\n",
        "\n",
        "def n_veces(fila, n):\n",
        "    \"\"\"Devuelve cuántas veces aparece `n` en una `fila` dada\"\"\"\n",
        "    cont = 0\n",
        "    for i in fila:\n",
        "        if i == n :\n",
        "            cont = cont + 1\n",
        "    return cont\n",
        "\n",
        "#Contamos con n=4\n",
        "resultado = []\n",
        "for fila in datos:\n",
        "    resultado.append(n_veces(fila, n=4))\n",
        "\n",
        "#Muestra cuántas veces está el número `4` en las 10 primeras filas                   \n",
        "print(resultado[:10])\n",
        "\n",
        "inicio = time.time()\n",
        "fin = time.time()\n",
        "\n",
        "print('Tiempo (en segundos)', fin - inicio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEYJzolT_xKw"
      },
      "source": [
        "## Paralelización con la clase `Process`\n",
        "\n",
        "Con la clase `Process` podemos crear nuevos procesos. Para la transferencia de datos entre los procesos se pueden usar colas (`Queues`) o tuberías (`Pipes`). En este ejemplo se usa una cola. Es necesario modificar la función `n_veces` para añadir la cola como parámetro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnDT5xK1_xKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af065248-c676-4172-8b79-5d32df301ff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 0, 0, 2, 1, 2, 1, 1, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "# Paralelización con la clase Process\n",
        "\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def n_veces_q(q, fila, n):\n",
        "    \"\"\"Devuelve cuántas veces aparece `n` en una `fila` dada\"\"\"\n",
        "    cont = 0\n",
        "    for i in fila:\n",
        "        if i == n :\n",
        "            cont = cont + 1\n",
        "    q.put(cont) \n",
        "\n",
        "q = Queue()\n",
        "resultado = []\n",
        "for fila in datos:\n",
        "    p = Process(target=n_veces_q, args=(q, fila, 4,))\n",
        "    p.start()\n",
        "    resultado.append(q.get())\n",
        "    \n",
        "p.join()\n",
        "\n",
        "print(resultado[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_f78VSI_xKw"
      },
      "source": [
        "## Paralelización con la clase `Pool`\n",
        "\n",
        "La forma general de paralelizar es iniciar un `Pool` con `n` procesos y pasar la función con alguno de los métodos de paralelización.\n",
        "\n",
        "El método `cpu_count` nos devuelve el número de *cores*.\n",
        "\n",
        "`multiprocessing.Pool()` proporciona los métodos `apply()`, `map()` y `starmap()` para que una función se ejecute en paralelo. La diferencia entre `apply()` y `map()` es que `apply()` tiene el argumento *args* que acepta los parámetros pasados a la función a paralelizar como un argumento, mientras que `map()` admite únicamente un iterable como argumento."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paralelización mediante `Pool.apply()`"
      ],
      "metadata": {
        "id": "-EOTIOS9KAki"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSk717hg_xKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f82772-60b1-4eb9-95dd-87dcd5775b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 0, 0, 2, 1, 2, 1, 1, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "# Paralelización mediante Pool.apply()\n",
        "\n",
        "import multiprocessing as mp\n",
        "\n",
        "# Paso 1: Iniciar multiprocessing.Pool()\n",
        "pool = mp.Pool(mp.cpu_count())\n",
        "\n",
        "# Paso 2: `pool.apply` a `n_veces`\n",
        "resultado = [pool.apply(n_veces, args=(fila, 4)) for fila in datos]\n",
        "\n",
        "# Paso 3: Cerrar\n",
        "pool.close()    \n",
        "\n",
        "print(resultado[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGXMhpRL_xKx"
      },
      "source": [
        "### Paralelización mediante `Pool.map()`\n",
        "`Pool.map()` acepta un único iterable como argumento. Vamos a modificar la función `n_veces` asignando un valor por defecto a *n*. Así, la nueva función sólo acepta una lista iterable de filas como entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF5gPL5F_xKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79124e5a-0f5c-459b-963f-367a0221e52f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 0, 0, 2, 1, 2, 1, 1, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "#  Paralelización mediante Pool.map()\n",
        "\n",
        "import multiprocessing as mp\n",
        "\n",
        "# Redefinir la función con un único argumento requerido.\n",
        "def n_veces_un_arg(fila, n=4):\n",
        "    cont = 0\n",
        "    for i in fila:\n",
        "        if i == n :\n",
        "            cont = cont + 1\n",
        "    return cont\n",
        "\n",
        "pool = mp.Pool(mp.cpu_count())\n",
        "\n",
        "resultado = pool.map(n_veces_un_arg, [fila for fila in datos])\n",
        "\n",
        "pool.close()\n",
        "\n",
        "print(resultado[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFJoVN7v_xKx"
      },
      "source": [
        "### Paralelización mediante `Pool.starmap()`\n",
        "\n",
        "En el ejemplo anterior hemos tenido que redefinir la función para que tuviera un único argumento requerido. En `Pool.starmap()`, cada elemento de su argumento iterable es también un iterable. Podemos pasarle los argumentos a la función a paralelizar en el mismo orden en este elemento iterable interno. De esta manera evitamos tener que modificar la función."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i6oMdx8_xKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b6411f3-2738-47b0-d834-1ddfe864ab95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 0, 0, 2, 1, 2, 1, 1, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "# Parallelizing with Pool.starmap()\n",
        "import multiprocessing as mp\n",
        "\n",
        "pool = mp.Pool(mp.cpu_count())\n",
        "\n",
        "resultado = pool.starmap(n_veces, [(fila, 4) for fila in datos])\n",
        "\n",
        "pool.close()\n",
        "\n",
        "print(resultado[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxtsWw0R_xKy"
      },
      "source": [
        "## Paralelización asíncrona\n",
        "\n",
        "Los métodos equivalentes asíncronos `apply_async()`, `map_async()` y `starmap_async()` permiten ejecutar los procesos paralelos de forma asíncrona, En este caso, no se puede garantizar en qué orden se obtendrán los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paralelización mediante `Pool.apply_async()`\n",
        "`apply_async()` es muy similar a `apply()` excepto que hay que proporcionar una función de retrollamada (*callback*) que avisa cuando los resultados estén disponibles.\n",
        "\n",
        "Como los procesos no tienen por qué terminar en el mismo orden en el que se iniciaron, vamos a redefir la función `n_veces2` con un parámetro para controlar el número de iteración *j* y poder ordenar los resultados finales."
      ],
      "metadata": {
        "id": "6XrLsa6FM3sb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McLAYULu_xKy"
      },
      "outputs": [],
      "source": [
        "# Paralelización mediante Pool.apply_async()\n",
        "\n",
        "import multiprocessing as mp\n",
        "pool = mp.Pool(mp.cpu_count())\n",
        "\n",
        "resultados = []\n",
        "\n",
        "# Redefinir para incluir el número de iteración `j`, \n",
        "def n_veces2(j, fila, n):\n",
        "    \"\"\"Devuelve cuántas veces aparece `n` en una `fila` dada\"\"\"\n",
        "    cont = 0\n",
        "    for i in fila:\n",
        "        if i == n :\n",
        "            cont = cont + 1\n",
        "    return (j,cont)\n",
        "\n",
        "# Definir la función callback para recoger los `resultados`\n",
        "def recoger_resultados(res):\n",
        "    global resultados\n",
        "    resultados.append(res)\n",
        "\n",
        "# Usar un bucle para paralelizar\n",
        "for i, fila in enumerate(datos):\n",
        "    pool.apply_async(n_veces2, args=(i, fila, 4), callback=recoger_resultados)\n",
        "\n",
        "# Cerrar el Pool y permitir que terminen todos los procesos    \n",
        "pool.close()\n",
        "pool.join()  # garantiza que la siguiente línea se ejecute después de que terminen todos los procesos\n",
        "\n",
        "# Ordenar resultados (opcional)\n",
        "#resultados.sort(key=lambda x: x[0])\n",
        "\n",
        "resultados_finales = [r for i, r in resultados]\n",
        "\n",
        "print(resultados_finales[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmA_qSsf_xKy"
      },
      "source": [
        "También se puede implementar sin utilizar una función *callback*. En este caso, es necesario usar el método `pool.ApplyResult.get()` para recoger el resultado final deseado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgmDfZzn_xKy"
      },
      "outputs": [],
      "source": [
        "# Paralelización mediante Pool.apply_async() sin función callback\n",
        "\n",
        "import multiprocessing as mp\n",
        "pool = mp.Pool(mp.cpu_count())\n",
        "\n",
        "resultados = []\n",
        "\n",
        "# Llamar a apply_async() sin callback\n",
        "lista_res = [pool.apply_async(n_veces2, args=(i, fila, 4)) for i, fila in enumerate(datos)]\n",
        "\n",
        "# lista_res es una lista de objetos pool.ApplyResult\n",
        "resultados = [r.get()[1] for r in lista_res]\n",
        "\n",
        "# Cerrar el Pool y permitir que terminen todos los procesos\n",
        "pool.close()\n",
        "pool.join() # garantiza que la siguiente línea se ejecute después de que terminen todos los procesos\n",
        "\n",
        "print(resultados[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkvl14FI_xKy"
      },
      "source": [
        "### Paralelización mediante `Pool.map_async()`\n",
        "\n",
        "Versión asíncrona de `Pool.map()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4_7WQ5S_xKz"
      },
      "outputs": [],
      "source": [
        "# Paralelización mediante Pool.map_async()\n",
        "\n",
        "import multiprocessing as mp\n",
        "\n",
        "# Redefinir la función con un único argumento requerido.\n",
        "def n_veces_un_arg(fila, n=4):\n",
        "    cont = 0\n",
        "    for i in fila:\n",
        "        if i == n :\n",
        "            cont = cont + 1\n",
        "    return cont\n",
        "\n",
        "pool = mp.Pool(mp.cpu_count())\n",
        "\n",
        "resultados = []\n",
        "\n",
        "# Com map, hay que usar `n_veces_un_arg`\n",
        "resultados = pool.map_async(n_veces_un_arg, [fila for fila in datos]).get()\n",
        "\n",
        "pool.close()\n",
        "\n",
        "print(resultados[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3Bj2Eov_xKz"
      },
      "source": [
        "### Paralelización mediante Pool.starmap_async()\n",
        "\n",
        "Versión asíncrona de `Pool.starmap()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUm21uzR_xKz"
      },
      "outputs": [],
      "source": [
        "# Paralelización mediantePool.starmap_async()\n",
        "\n",
        "import multiprocessing as mp\n",
        "\n",
        "pool = mp.Pool(mp.cpu_count())\n",
        "\n",
        "resultados = []\n",
        "\n",
        "resultados = pool.starmap_async(n_veces2, [(i, fila, 4) for i, fila in enumerate(datos)]).get()\n",
        "\n",
        "pool.close()\n",
        "\n",
        "resultados_finales = [r for i, r in resultados]\n",
        "print(resultados_finales[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs29tl0f_xKz"
      },
      "source": [
        "# Ejemplo: Paralelizar un DataFrame de Pandas\n",
        "Los DataFrame de Pandas y los arrays de Numpy son los objetos más usados para almacenar datos tabulados en Ciencia de Datos.\n",
        "\n",
        "Cuando queramos paralelizar un DataFrame, podemos crear una función paralelizable que tenga como parámetro de entrada:\n",
        "\n",
        "* una fila del dataframe\n",
        "* una columna del dataframe\n",
        "* el dataframe entero\n",
        "\n",
        "Para los dos primeros casos, se puede usar el módulo **multiprocessing**.  Pero, para paralelizar el dataframe entero vamos a usar el paquete **pathos**.\n",
        "\n",
        "Creamos primero un dataframe de tamaño 5x2 con valores entre 0 y 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IvE3qz1_xKz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import multiprocessing as mp\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(1, 10, size=[5, 2]))\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfnwoW28_xKz"
      },
      "source": [
        "## Paralelizando un dataframe por filas\n",
        "\n",
        "Vamos a aplicar la función *hipotenusa* a cada fila, ejecutando sobre 4 procesos en paralelo. Usaremos `df.itertuples(name=None)` para pasar cada fila del dataframe como una tupla a la función hipotenusa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOGRJEju_xK0"
      },
      "outputs": [],
      "source": [
        "# Operación sobre las filas\n",
        "\n",
        "import multiprocessing as mp\n",
        "\n",
        "def hipotenusa(fila):\n",
        "    return round(fila[1]**2 + fila[2]**2, 2)**0.5\n",
        "\n",
        "cores=mp.cpu_count()\n",
        "\n",
        "with mp.Pool(cores) as pool:\n",
        "    resultado = pool.imap(hipotenusa, df.itertuples(name=None), chunksize=10)\n",
        "    salida = [round(x, 2) for x in resultado]\n",
        "    \n",
        "print(salida) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnVxaNwU_xK0"
      },
      "source": [
        "## Paralelizando un dataframe por columnas\n",
        "En este ejemplo, vamos a aplicar la función `suma_de_cuadrados` a cada columna, ejecutando sobre 2 procesos en paralelo. Usaremos el método `df.iteritems()` para pasar cada columna del dataframe a la función hipotenusa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utr_P3XK_xK0"
      },
      "outputs": [],
      "source": [
        "# Operación sobre columnas\n",
        "\n",
        "def suma_de_cuadrados(columna):\n",
        "    return sum([i**2 for i in columna[1]])\n",
        "\n",
        "with mp.Pool(2) as pool:\n",
        "    resultado = pool.imap(suma_de_cuadrados, df.iteritems(), chunksize=10)\n",
        "    salida = [x for x in resultado]\n",
        "\n",
        "print(salida)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPXxRYgl_xK0"
      },
      "source": [
        "## Paralelizando un dataframe entero\n",
        "En este ejemplo se procesa un DataFrame entero usando el paquete **pathos**. Pathos sigue el patrón de multiprocesamiento:\n",
        "Pool > Map > Close > Join > Clear\n",
        "\n",
        "NOTA: Es necesario installar antes el paquete **pathos**: "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pathos"
      ],
      "metadata": {
        "id": "bTO5lq3QNBvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkDQwHXp_xK1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import multiprocessing as mp\n",
        "from pathos.multiprocessing import ProcessingPool as Pool\n",
        "\n",
        "# crear un dataframe \n",
        "df = pd.DataFrame(np.random.randint(1, 10, size=[1000, 2]))\n",
        "\n",
        "# mostrar los primeros elementos del dataframe\n",
        "print(df.head())\n",
        "\n",
        "# Definir una función que devuelva las dimensiones de un dataframe\n",
        "def func(df):\n",
        "    return df.shape\n",
        "\n",
        "# obtener el número de cores\n",
        "cores=mp.cpu_count()\n",
        "\n",
        "# dividir el DataFrame según el número de cores\n",
        "df_split = np.array_split(df, cores, axis=0)\n",
        "\n",
        "# Crear un pool de procesos\n",
        "pool = Pool(cores)\n",
        "\n",
        "# procesar el DataFrame mapeando la función func a cada df_split en el pool\n",
        "df_salida = np.vstack(pool.map(func, df_split))\n",
        "\n",
        "# cerrar el pool, join y clear\n",
        "pool.close()\n",
        "pool.join()\n",
        "pool.clear()\n",
        "\n",
        "print(df_salida)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVmuQ7Xp_xK1"
      },
      "source": [
        "# Ejercicios\n",
        "\n",
        "1. Vuelve a ejecutar los ejemplos anteriores con distintos tamaños de la matriz *datos* y comprobando los tiempos de ejecución.\n",
        "2. Dada la siguiente función de normalización, usa `pool.apply()` para normalizar, en cada fila, los valores de la matriz *datos* para que varíen entre 0 y 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "vyto6tRU_xK1"
      },
      "outputs": [],
      "source": [
        "def normalizar(lista):\n",
        "    mini = min(lista)\n",
        "    maxi = max(lista)\n",
        "    return [(i - mini)/(maxi-mini) for i in lista]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Paralelizacion_Python_AlvaroMartinez.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}